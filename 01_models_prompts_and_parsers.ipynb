{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "corc3Qd5fm47"
      },
      "outputs": [],
      "source": [
        "%pip install -q -U langchain langchain-google-genai google_generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip show langchain"
      ],
      "metadata": {
        "id": "9cWUl6RlhgX1",
        "outputId": "861686bc-f5ef-462c-daf1-2625897db646",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.3.4\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, async-timeout, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "from google.generativeai import GenerativeModel\n",
        "\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "llm: GenerativeModel = GenerativeModel(\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "4Viw87tChl81"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt: str, model=llm) -> str:\n",
        "  response = model.generate_content(prompt)\n",
        "  return response.text\n",
        "\n",
        "get_completion(\"What is 9 + 1?\")"
      ],
      "metadata": {
        "id": "ED9g2hgljFWM",
        "outputId": "6ccf5359-7c29-430e-da0f-7ffcca3f6f3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'9 + 1 = 10 \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_email = \"\"\"\n",
        "Arrr, I be fuming that me blender lid \\\n",
        "flew off and splattered me kitchen walls \\\n",
        "with smoothie! And to make matters worse,\\\n",
        "the warranty don't cover the cost of \\\n",
        "cleaning up me kitchen. I need yer help \\\n",
        "right now, matey!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "eeB-PxNkkS6X"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "style = \"\"\"American English \\\n",
        "in a calm and respectful tone\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KHho3q5dkWcV"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Translate the text \\\n",
        "that is delimited by triple backticks\n",
        "into a style that is {style}.\n",
        "text: ```{customer_email}```\n",
        "\"\"\"\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "r3mR_vE9kZQN",
        "outputId": "fe34afb3-c150-4fa0-d2bc-52115f7b9fb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translate the text that is delimited by triple backticks\n",
            "into a style that is American English in a calm and respectful tone\n",
            ".\n",
            "text: ```\n",
            "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = get_completion(prompt)\n",
        "res"
      ],
      "metadata": {
        "id": "w93qdQDaklJt",
        "outputId": "c8e11f66-0381-4b47-fd91-7bdb773ab172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm quite frustrated that the lid of my blender came off and splattered smoothie all over my kitchen walls. To make matters worse, the warranty doesn't cover the cost of cleaning up the mess. I would appreciate any advice you can offer. \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini using LangChain\\\n",
        "Now doing the same using LangChain."
      ],
      "metadata": {
        "id": "gWG-b0arpc3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm: ChatGoogleGenerativeAI =  ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.0, api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "AqQfAmS6ptoH"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "id": "BJis_yiqtFmP",
        "outputId": "78749dff-7a7e-42b1-dc5a-f28c8a958e8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), temperature=0.0, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7f0916ca0c10>, default_metadata=())"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template_string = \"\"\"Translate the text \\\n",
        "that is delimited by triple backticks \\\n",
        "into a style that is {style}. \\\n",
        "text: ```{text}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jln3EakTttBI"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
        "\n",
        "# print(prompt_template)\n",
        "\n",
        "# print(prompt_template.messages[0].prompt)\n",
        "\n",
        "prompt_template.messages[0].prompt.input_variables"
      ],
      "metadata": {
        "id": "azJs3dl2tzip",
        "outputId": "135ed40f-8372-4b54-cf03-5ca48d0e7c6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['style', 'text']"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_style = \"\"\"American English \\\n",
        "in a calm and respectful tone\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "eHAnXiGBvaoV"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_email = \"\"\"\n",
        "Arrr, I be fuming that me blender lid \\\n",
        "flew off and splattered me kitchen walls \\\n",
        "with smoothie! And to make matters worse, \\\n",
        "the warranty don't cover the cost of \\\n",
        "cleaning up me kitchen. I need yer help \\\n",
        "right now, matey!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hHUpjQ84vdVm"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_message = prompt_template.format_messages(style=customer_style, text=customer_email)\n",
        "\n",
        "# customer_message\n",
        "customer_message[0]"
      ],
      "metadata": {
        "id": "83qHLsO8vg5e",
        "outputId": "8954d663-940c-4207-a107-dff1d05f6797",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HumanMessage(content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\", additional_kwargs={}, response_metadata={})"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(customer_message))\n",
        "print(type(customer_message[0]))"
      ],
      "metadata": {
        "id": "RPKtSxB3wVkg",
        "outputId": "73f0463f-cc0e-471f-a9fc-92d303ffeaaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'langchain_core.messages.human.HumanMessage'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = llm.invoke(customer_message)\n",
        "\n",
        "# res\n",
        "res.content"
      ],
      "metadata": {
        "id": "PHOd6Z-Ywq1p",
        "outputId": "bdde25a4-24cc-45b8-9309-935100ffda8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm quite frustrated that my blender lid came off and splattered smoothie all over my kitchen walls. To make matters worse, the warranty doesn't cover the cost of cleaning up the mess. I could really use your help right now. \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3.12.4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}